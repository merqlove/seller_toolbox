{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, Markdown as md\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from scrapinghub import ScrapinghubClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# загружаем конфиг\n",
    "with open('config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные выгружаются напрямую из Scrapinghub по API. Нужный датасет (или даже нужные датасеты, их можно быть много) ищутся по их тегу. Чтобы все работало, в конфиге тулбокса (файл `config.yaml`) нужно в параметре `category_dashboard:job_tag_filter` указать название тэга выгрузки Scrapinghub, по которой нужно выгружать данные. Скрипт выгрузит результаты работы всех завершенных задач с указанным тегом. Тег в Scrapinghub нужно указать при создании выгрузки данных (job).\n",
    "\n",
    "Дальше этот датасет будет сохранен в папку data директории, в которой находится блокнт. Если в папке уже лежит файл с названием вида `category_dashboard_*.csv`, то новые данные загружены не будут.\n",
    "\n",
    "Нужный файл можно положить и вручную, скачав его из Scrapinghub. Можно даже положить несколько файлов – скрипт возьмет последний по алфавиту.\n",
    "\n",
    "После изменения переменной с тегом в Юпитере нужно выбрать пункт меню \"Run -> Run All Cells\". Дальше блокнот сделает все сам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# здесь нужно указать тэг нужной выгрузки, по-умолчанию он берется из конфига\n",
    "job_tag_filter = config['category_dashboard']['job_tag_filter']\n",
    "\n",
    "# остальное лучше не трогать\n",
    "api_key = config['scrapinghub']['api_key']\n",
    "project_id = config['scrapinghub']['project_id']\n",
    "csv_name =  './data/category_dashboard_' + str(datetime.now()) + '.csv'\n",
    "\n",
    "def load_data(job_tag_filter, api_key, project_id, csv_name):\n",
    "    client = ScrapinghubClient(api_key)\n",
    "    project = client.get_project(project_id)\n",
    "    fieldnames = []\n",
    "    \n",
    "    jobs_summary = project.jobs.iter(has_tag=[job_tag_filter], state='finished')\n",
    "    \n",
    "    # определяем поля выгрузки\n",
    "    for job in jobs_summary:\n",
    "        for item in client.get_job(job['key']).items.iter():\n",
    "            fieldnames = item.keys()\n",
    "            break\n",
    "        break\n",
    "    \n",
    "    # готовим CSV\n",
    "    with open(csv_name, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        jobs_summary = project.jobs.iter(has_tag=[job_tag_filter], state='finished')\n",
    "\n",
    "        for job in jobs_summary:\n",
    "            for item in client.get_job(job['key']).items.iter():\n",
    "                writer.writerow(item)\n",
    "\n",
    "load_data(job_tag_filter, api_key, project_id, csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "latest_csv = sorted(glob.glob('./data/category_dashboard_*.csv'), reverse=True)[0]\n",
    "data = pd.read_csv(latest_csv)\n",
    "\n",
    "# сложная конструкция для исключения NaN значений цен (иногда проскакивают)\n",
    "data = data[~np.isnan(data['wb_price'])]\n",
    "data = data[~np.isnan(data['wb_purchases_count'])]\n",
    "\n",
    "data['wb_turnover'] = data['wb_price'] * data['wb_purchases_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data\n",
    "\n",
    "data.loc[0].at['product_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Статистика цен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные описательные статистики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "md(\"Показатель | Значение\\n--- | ---\\nКоличество товаров | {}\\nКоличество продаж | {}\\nСредние продажи  | {}\\nМедиана продаж | {}\\nСамый дорогой (руб) | {}\\nСамый дешевый (руб) | {}\\nСредняя цена | {}\".format(len(data.index), data['wb_purchases_count'].sum(), round(data['wb_purchases_count'].mean(), 2), round(data['wb_purchases_count'].median(), 2), data['wb_price'].max(), data['wb_price'].min(), round(data['wb_price'].mean(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение цен на товары в разделе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(data['wb_price'], rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Статистика продаж"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение количества продаж:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(data['wb_purchases_count'], rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Статистика рейтингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение рейтингов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(data['wb_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение количества отзывов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(data['wb_reviews_count'], rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парные зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "g = sns.PairGrid(data, vars=[\"wb_rating\", \"wb_reviews_count\", \"wb_price\", \"wb_purchases_count\"])\n",
    "g.map(plt.scatter);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
